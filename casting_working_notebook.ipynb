{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from database_utils import DatabaseConnector\n",
    "import re \n",
    "from sqlalchemy import create_engine, text, insert \n",
    "from sqlalchemy.inspection import inspect\n",
    "from sqlalchemy.exc import SQLAlchemyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#START HERE FROM 22th JULY \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_my_db_engine is working\n",
      "read_my_db_creds is working\n",
      "Connection to the PostgreSQL database was successful!\n",
      "Column type before conversion: ('store_type', 'character varying')\n",
      "Column type after conversion: ('store_type', 'character varying')\n",
      "End of call\n"
     ]
    }
   ],
   "source": [
    "# CURRENT CODE  \n",
    "\n",
    "\n",
    "# HELPER FUNCTIONS \n",
    "\n",
    "# Create function to fetch data from the table in my local SQL server so that I can get the data to perform checks on it \n",
    "def fetch_data(connection, table_name, limit=5):\n",
    "    fetch_data_query = f\"SELECT * FROM {table_name} LIMIT {limit};\"\n",
    "    result = connection.execute(text(fetch_data_query))\n",
    "    return result.fetchall()\n",
    "\n",
    "# Function to check the column data type to check if the column type has been correctly converted \n",
    "def check_column_type(connection, table_name, column_name):\n",
    "    check_column_type_query = f\"\"\"\n",
    "        SELECT column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = '{table_name}' AND column_name = '{column_name}';\n",
    "    \"\"\"\n",
    "    result = connection.execute(text(check_column_type_query))\n",
    "    return result.fetchone()\n",
    "\n",
    "# Function to determine the maximum length of values in the column\n",
    "def get_max_length(connection, table_name, column_name):\n",
    "    max_length_sql = f\"\"\"\n",
    "    SELECT MAX(LENGTH(CAST({column_name} AS TEXT))) \n",
    "    FROM {table_name};\n",
    "    \"\"\"\n",
    "    result = connection.execute(text(max_length_sql)).fetchone()\n",
    "    return result[0]\n",
    "\n",
    "def remove_pound_symbol(connection, table_name, column_name):\n",
    "    remove_pound_sql = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET {column_name} = REPLACE({column_name}, '£', '')\n",
    "    WHERE {column_name} LIKE '£%';\n",
    "    \"\"\"\n",
    "    connection.execute(text(remove_pound_sql))\n",
    "\n",
    "def add\n",
    "\n",
    "# CLEANING FUNCTIONS \n",
    "\n",
    "# Create function to clean uuid with regex #working regex:   WHERE TRIM(CAST({column_name} AS TEXT)) !~* '^[a-f0-9\\\\-]+$';\n",
    "def clean_uuid(connection, table_name, column_name):\n",
    "    clean_uuid = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET {column_name} = NULL\n",
    "    WHERE TRIM(CAST({column_name} AS TEXT)) !~* '^[a-f0-9]{{8}}-[a-f0-9]{{4}}-[a-f0-9]{{4}}-[a-f0-9]{{4}}-[a-f0-9]{{12}}$';\n",
    "    \"\"\"  \n",
    "    # Convert the SQL string to a TextClause object and execute the query\n",
    "    connection.execute(text(clean_uuid))\n",
    "\n",
    "# 9476f17e-5d6a-4117-874d-9cdb38ca1fa6\n",
    "\n",
    "# Create function to clean numeric data (both integer and floats) data with regex by ensuring they are numbers \n",
    "def clean_numbers(connection, table_name, column_name):\n",
    "    clean_numbers_sql = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET {column_name} = NULL\n",
    "    WHERE CAST({column_name} AS TEXT) !~ '^[-]?[0-9]*\\\\.?[0-9]+$';\n",
    "    \"\"\"\n",
    "    connection.execute(text(clean_numbers_sql))\n",
    "\n",
    "# Create function to clean store_code and product_code data with regex (e.g. store_code 'BL-8387506C', product_code 'R7-3126933h')\n",
    "def clean_store_or_product_codes(connection, table_name, column_name):\n",
    "    clean_numbers_sql = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET {column_name} = NULL\n",
    "    WHERE CAST({column_name} AS TEXT) !~ '^[A-Za-z0-9]+-[A-Za-z0-9]+$';\n",
    "    \"\"\"\n",
    "    connection.execute(text(clean_numbers_sql))\n",
    "\n",
    "# cleaning text data  \n",
    "def clean_text_data(connection, table_name, column_name):\n",
    "    clean_text_sql = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET {column_name} = NULL\n",
    "    WHERE CAST({column_name} AS TEXT) !~ '^[A-Za-z]+$';\n",
    "    \"\"\"\n",
    "    connection.execute(text(clean_text_sql))\n",
    "\n",
    "def clean_date_data(connection, table_name, column_name):\n",
    "    clean_date_sql = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET {column_name} = \n",
    "    TO_DATE(\n",
    "        REGEXP_REPLACE(\n",
    "            CAST({column_name} AS TEXT), \n",
    "            '\\\\((\\\\d+), (\\\\d+), (\\\\d+), \\\\d+, \\\\d+\\\\)', \n",
    "            '\\\\1-\\\\2-\\\\3'\n",
    "        ), \n",
    "        'YYYY-MM-DD'\n",
    "    )\n",
    "    WHERE CAST({column_name} AS TEXT) ~ '\\\\(\\\\d+, \\\\d+, \\\\d+, \\\\d+, \\\\d+\\\\)';\n",
    "    \"\"\"\n",
    "    connection.execute(text(clean_date_sql))\n",
    "\n",
    "# CONVERTING FUNCTIONS  \n",
    "\n",
    "# Create function to convert a specified column to UUID \n",
    "def convert_to_uuid(connection, table_name, column_name): \n",
    "    convert_date_uuid = f\"\"\"\n",
    "        ALTER TABLE {table_name}\n",
    "        ALTER COLUMN {column_name} TYPE UUID\n",
    "        USING {column_name}::UUID;\n",
    "        \"\"\"\n",
    "    # Convert the SQL string to a TextClause object and execute the query\n",
    "    connection.execute(text(convert_date_uuid))\n",
    "\n",
    "# Function to convert the column to VARCHAR with the determined maximum length // goes after USING CAST: ALTER COLUMN {column_name} DROP NOT NULL;\n",
    "def convert_to_varchar(connection, table_name, column_name, length): \n",
    "    convert_to_var_sql = f\"\"\"\n",
    "    ALTER TABLE {table_name}\n",
    "    ALTER COLUMN {column_name} TYPE VARCHAR({length}) USING CAST({column_name} AS VARCHAR({length})),\n",
    "    ALTER COLUMN {column_name} DROP NOT NULL;\n",
    "    \"\"\"\n",
    "    connection.execute(text(convert_to_var_sql))\n",
    "\n",
    "# Create function to convert bigint to smalint \n",
    "def convert_to_smallint(connection, table_name, column_name): \n",
    "    convert_date_uuid = f\"\"\"\n",
    "        ALTER TABLE {table_name}\n",
    "        ALTER COLUMN {column_name} TYPE SMALLINT\n",
    "        USING CAST({column_name} AS SMALLINT);\n",
    "        \"\"\"\n",
    "    # Convert the SQL string to a TextClause object and execute the query\n",
    "    connection.execute(text(convert_date_uuid))\n",
    "\n",
    "# Create function to convert to date \n",
    "def convert_to_date(connection, table_name, column_name): \n",
    "    convert_date_sql = f\"\"\"\n",
    "    ALTER TABLE {table_name}\n",
    "    ALTER COLUMN {column_name} TYPE DATE\n",
    "    USING {column_name}::DATE;\n",
    "    \"\"\"\n",
    "    connection.execute(text(convert_date_sql))\n",
    "\n",
    "# Create function to convert date to  to smalint \n",
    "def convert_to_float(connection, table_name, column_name): \n",
    "    convert_date_sql = f\"\"\"\n",
    "    ALTER TABLE {table_name}\n",
    "    ALTER COLUMN {column_name} TYPE FLOAT\n",
    "    USING {column_name}::FLOAT;\n",
    "    \"\"\"\n",
    "    connection.execute(text(convert_date_sql))\n",
    "\n",
    "# Function to run all operations\n",
    "def run_all_operations():\n",
    "    \n",
    "    # Create instance of a DatabaseConnector  \n",
    "    instance = DatabaseConnector() \n",
    "    # Create an engine by using the init_my_db_engine() method of DatabaseConnector \n",
    "    engine = instance.init_my_db_engine()\n",
    "    \n",
    "    #try to do engine.connect() \n",
    "    with engine.connect() as connection:\n",
    "    \n",
    "        with connection.begin():  # Ensure the transaction is committed\n",
    "            \n",
    "            # Check and print column type before conversion\n",
    "            column_type_before = check_column_type(connection, 'dim_store_details', 'store_type')\n",
    "            print(f\"Column type before conversion: {column_type_before}\")\n",
    "            \n",
    "            #put the attempt to run the functions in a try block \n",
    "            try:\n",
    "                # Cleaning then converting the date_uuid\n",
    "                clean_uuid(connection, 'orders_table', 'date_uuid')\n",
    "                #print('Clean UUID worked')\n",
    "                convert_to_uuid(connection, 'orders_table', 'date_uuid')\n",
    "                #print('Convert to UUID worked')\n",
    "                \n",
    "                # Cleaning then converting the user_uuid\n",
    "                clean_uuid(connection, 'orders_table', 'user_uuid')\n",
    "                #print('Clean UUID worked')\n",
    "                convert_to_uuid(connection, 'orders_table', 'user_uuid')\n",
    "                #print('Convert to UUID worked')\n",
    "                \n",
    "                # Cleaning then converting the card_number\n",
    "                clean_numbers(connection, 'orders_table', 'card_number')\n",
    "                #print('Clean card numbers worked')\n",
    "                max_length = get_max_length(connection, 'orders_table', 'card_number')\n",
    "                convert_to_varchar(connection, 'orders_table', 'card_number', max_length)\n",
    "                #print('Convert card numbers worked')\n",
    "\n",
    "                # Cleaning then converting store_code\n",
    "                clean_store_or_product_codes(connection, 'orders_table', 'store_code')\n",
    "                max_length = get_max_length(connection, 'orders_table', 'store_code')\n",
    "                #print('clean store_code worked)')\n",
    "                #print(max_length)\n",
    "                convert_to_varchar(connection, 'orders_table', 'store_code', max_length)\n",
    "                #print('Convert store_code worked')\n",
    "\n",
    "                # Cleaning then converting product_code\n",
    "                clean_store_or_product_codes(connection, 'orders_table', 'product_code')\n",
    "                max_length = get_max_length(connection, 'orders_table', 'product_code')\n",
    "                #print('clean product_code worked)')\n",
    "                #print(max_length)\n",
    "                convert_to_varchar(connection, 'orders_table', 'product_code', max_length)\n",
    "                #print('Convert product_code worked')\n",
    "\n",
    "                # Cleaning then converting the product_quantity\n",
    "                clean_numbers(connection, 'orders_table', 'product_quantity')\n",
    "                #print('Clean product quantity has worked')\n",
    "                convert_to_smallint(connection, 'orders_table', 'product_quantity')\n",
    "                #print('Convert product quantity has worked')\n",
    "\n",
    "                # Cleaning then converting first_name\n",
    "                clean_text_data(connection, 'dim_users', 'first_name')\n",
    "                #print('Clean first_name has worked')\n",
    "                convert_to_varchar(connection, 'dim_users', 'first_name', 255)\n",
    "                #print('Convert first_name worked')\n",
    "\n",
    "                # Cleaning then converting first_name\n",
    "                clean_text_data(connection, 'dim_users', 'last_name')\n",
    "                #print('Clean last_name has worked')\n",
    "                convert_to_varchar(connection, 'dim_users', 'last_name', 255)\n",
    "                #print('Convert last_name worked')\n",
    "\n",
    "                # Cleaning then converting date_of_birth\n",
    "                clean_date_data(connection, 'dim_users', 'date_of_birth')\n",
    "                #print('Date data cleaning worked')\n",
    "                convert_to_date(connection, 'dim_users', 'date_of_birth')\n",
    "                #print('Conversion to date worked')\n",
    "\n",
    "                # Cleaning then converting country_code \n",
    "                clean_text_data(connection, 'dim_users', 'country_code')\n",
    "                #print('clean country_code worked')\n",
    "                max_length = get_max_length(connection, 'dim_users', 'country_code')\n",
    "                #print('this is ', max_length)\n",
    "                convert_to_varchar(connection, 'dim_users', 'country_code', max_length)\n",
    "                #print('Convert country_code worked')\n",
    "\n",
    "                # Cleaning then converting the user_uuid\n",
    "                clean_uuid(connection, 'dim_users', 'user_uuid')\n",
    "                #print('Clean UUID worked')\n",
    "                convert_to_uuid(connection, 'dim_users', 'user_uuid')\n",
    "                #print('Convert to UUID worked')\n",
    "\n",
    "                # Cleaning then converting date_of_birth\n",
    "                clean_date_data(connection, 'dim_users', 'join_date')\n",
    "                #print('join_date cleaning worked')\n",
    "                convert_to_date(connection, 'dim_users', 'join_date')\n",
    "                #print('Conversion of join_date worked')\n",
    "                \n",
    "                # Cleaning then converting longitude\n",
    "                clean_numbers(connection, 'dim_store_details', 'longitude')\n",
    "                #print('longitude cleaning worked')\n",
    "                convert_to_float(connection, 'dim_store_details', 'longitude')\n",
    "                #print('Conversion of longitude worked')\n",
    "\n",
    "                # Cleaning then converting locality \n",
    "                clean_text_data(connection, 'dim_store_details', 'locality')\n",
    "                #print('Clean locality has worked')\n",
    "                convert_to_varchar(connection, 'dim_store_details', 'locality', 255)\n",
    "                #print('Convert locality worked')\n",
    "\n",
    "                # Cleaning then converting store_code \n",
    "                clean_store_or_product_codes(connection, 'dim_store_details', 'store_code')\n",
    "                #print('clean store_code worked')\n",
    "                max_length = get_max_length(connection, 'dim_store_details', 'store_code')\n",
    "                #print('this is ', max_length)\n",
    "                convert_to_varchar(connection, 'dim_store_details', 'store_code', max_length)\n",
    "                #print('Convert store_code worked')\n",
    "\n",
    "                # Cleaning then converting staff_numbers\n",
    "                clean_numbers(connection, 'dim_store_details', 'staff_numbers')\n",
    "                #print('staff_numbers cleaning worked')\n",
    "                convert_to_smallint(connection, 'dim_store_details', 'staff_numbers')\n",
    "                #print('Conversion of staff_numbers worked')\n",
    "                \n",
    "                # Cleaning then converting opening_date\n",
    "                clean_date_data(connection, 'dim_store_details', 'opening_date')\n",
    "                #print('opening_date cleaning worked')\n",
    "                convert_to_date(connection, 'dim_store_details', 'opening_date')\n",
    "                #print('Conversion of opening_date worked')\n",
    "\n",
    "                # Cleaning then converting locality \n",
    "                clean_text_data(connection, 'dim_store_details', 'store_type')\n",
    "                #print('Clean store_type has worked')\n",
    "                convert_to_varchar(connection, 'dim_store_details', 'store_type', 255)\n",
    "                #print('Convert store_type worked')\n",
    "\n",
    "                # Cleaning then converting longitude\n",
    "                clean_numbers(connection, 'dim_store_details', 'latitude')\n",
    "                #print('latitude cleaning worked')\n",
    "                convert_to_float(connection, 'dim_store_details', 'latitude')\n",
    "                #print('Conversion of latitude worked')\n",
    "\n",
    "                # Cleaning then converting country_code \n",
    "                clean_text_data(connection, 'dim_store_details', 'country_code')\n",
    "                #print('clean country_code worked')\n",
    "                max_length = get_max_length(connection, 'dim_store_details', 'country_code')\n",
    "                convert_to_varchar(connection, 'dim_store_details', 'country_code', max_length)\n",
    "                #print('Convert country_code worked')\n",
    "\n",
    "                # Cleaning then converting continent \n",
    "                clean_text_data(connection, 'dim_store_details', 'continent')\n",
    "                #print('Clean continent has worked')\n",
    "                convert_to_varchar(connection, 'dim_store_details', 'continent', 255)\n",
    "                #print('Convert continent worked')\n",
    "\n",
    "                # Removing pound from price column\n",
    "                remove_pound_symbol(connection, 'dim_products', 'product_price')\n",
    "                \n",
    "\n",
    "\n",
    "            except SQLAlchemyError as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "            # Check and print column type after conversion\n",
    "            column_type_after = check_column_type(connection, 'dim_store_details', 'store_type')\n",
    "            print(f\"Column type after conversion: {column_type_after}\")\n",
    "\n",
    "    print('End of call')\n",
    "\n",
    "run_all_operations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_my_db_engine is working\n",
      "read_my_db_creds is working\n",
      "Connection to the PostgreSQL database was successful!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RMKeyView(['index', 'address', 'longitude', 'locality', 'store_code', 'staff_numbers', 'opening_date', 'store_type', 'latitude', 'country_code', 'continent'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 'Heckerstraße 4/5\\n50491 Säckingen, Landshut', 48.52961, 'Landshut', 'LA-0772C7B9', 92, datetime.date(2013, 4, 12), 'Super Store', 12.16179, 'DE', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3, '5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury', 51.26, 'Westbury', 'WE-1DE82CEE', 69, datetime.date(2014, 1, 2), 'Super Store', -2.1875, 'GB', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4, 'Studio 6\\nStephen landing\\nSouth Simon\\nB77 2WA, Belper', 53.0233, 'Belper', 'BE-18074576', 35, datetime.date(2019, 9, 9), 'Local', -1.48119, 'GB', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5, 'Flat 92u\\nChristian harbors\\nPort Charlotte\\nN57 8FJ, Gainsborough', 53.38333, 'Gainsborough', 'GA-CAD01AC2', 36, datetime.date(1995, 5, 15), 'Local', -0.76667, 'GB', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6, '7 Gillian rue\\nWest Robertside\\nPH4 8NY, Rutherglen', 55.82885, 'Rutherglen', 'RU-C603E990', 92, datetime.date(2001, 1, 4), 'Super Store', -4.21376, 'GB', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7, 'Lilija-Heß-Allee 660\\n34566 Regensburg, Stuttgart', 48.78232, 'Stuttgart', 'ST-229D997E', 34, datetime.date(2000, 6, 1), 'Local', 9.17702, 'DE', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8, '510 Jill Mill\\nSouth Laura, FL 38723, Kaukauna', 44.27804, 'Kaukauna', 'KA-FA7ED3B8', 31, datetime.date(2022, 9, 5), 'Local', -88.27205, 'US', 'America')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9, '3 Lee valleys\\nWest Janetview\\nDY4M 2RL, Hartley', 51.38673, 'Hartley', 'HA-974352FE', 20, datetime.date(2004, 9, 11), 'Local', 0.30367, 'GB', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12, 'Flat 37\\nBennett expressway\\nNew Charlotte\\nSY8R 5WE, Devizes', 51.35084, 'Devizes', 'DE-585399CF', 36, datetime.date(2014, 10, 11), 'Local', -1.99421, 'GB', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14, 'Herma-Rädel-Gasse 29\\n74557 Fulda, Halstenbek', 53.63333, 'Halstenbek', 'HA-39A446E2', 38, datetime.date(1994, 3, 8), 'Local', 9.85, 'DE', 'Europe')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#THIS IS CODE SO THAT I CAN SEE WHAT THE TABLE LOOKS LIKE \n",
    "def view_data(): \n",
    "\n",
    "    instance = DatabaseConnector() \n",
    "\n",
    "    engine = instance.init_my_db_engine()\n",
    "\n",
    "\n",
    "    # Define the query to display column headers and first few rows :: dim_store_details\n",
    "    query = \"SELECT * FROM dim_store_details LIMIT 10;\" \n",
    "\n",
    "    # Use a context manager to handle the connection\n",
    "    with engine.connect() as connection:  \n",
    "        result = connection.execute(text(query))\n",
    "        # Print the column headers\n",
    "        display(result.keys())\n",
    "        # Print each row\n",
    "        for row in result:\n",
    "            display(row)\n",
    "\n",
    "view_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_my_db_engine is working\n",
      "read_my_db_creds is working\n",
      "Connection to the PostgreSQL database was successful!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RMKeyView(['first_name'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CHECK THAT ALL NAMES IN FIRST NAME COLUMN ARE ALPHABETIC \n",
    "\n",
    "def view_data(): \n",
    "    # Create engine \n",
    "    instance = DatabaseConnector() \n",
    "\n",
    "    engine = instance.init_my_db_engine()\n",
    "\n",
    "\n",
    "    # Define the query to display column headers and first few rows\n",
    "    query = \"SELECT first_name FROM dim_users LIMIT 5;\"\n",
    "\n",
    "    # Use a context manager to handle the connection\n",
    "    with engine.connect() as connection:  \n",
    "        result = connection.execute(text(query))\n",
    "        # Print the column headers\n",
    "        display(result.keys())\n",
    "        # Initialise the list to store the odd names \n",
    "        odd_names = []\n",
    "        # create the regex pattern\n",
    "        pattern = re.compile('^[A-Za-z]+$')\n",
    "        # iterate through each row in the result \n",
    "        for row in result:\n",
    "            # Access the first element of the tuple to get the name\n",
    "            name = row[0]\n",
    "            if not pattern.match(name):\n",
    "                odd_names.append(name)\n",
    "                 \n",
    "        #display(row)\n",
    "        display(odd_names)\n",
    "view_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve_stores_data is working\n",
      "read_api_key is working\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initial import\n",
    "from data_cleaning import DataCleaning\n",
    "from data_extraction import DataExtractor\n",
    "\n",
    "# creating instances \n",
    "extractor_instance = DataExtractor()\n",
    "cleaning_instance = DataCleaning()\n",
    "\n",
    "# get original dataframe \n",
    "raw_df = extractor_instance.retrieve_stores_data() \n",
    "\n",
    "# cleaning data\n",
    "#clean_store_df = cleaning_instance.cleaning_store_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>325</td>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>None</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>None</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.1875</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>None</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>446</td>\n",
       "      <td>Täschestraße 25\\n39039 Nördlingen, Kirchlengern</td>\n",
       "      <td>52.2</td>\n",
       "      <td>None</td>\n",
       "      <td>Kirchlengern</td>\n",
       "      <td>KI-78096E8C</td>\n",
       "      <td>61</td>\n",
       "      <td>2005-05-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>8.63333</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>447</td>\n",
       "      <td>K0ODETRLS3</td>\n",
       "      <td>K8CXLZDP07</td>\n",
       "      <td>UXMWDMX1LC</td>\n",
       "      <td>3VHFDNP8ET</td>\n",
       "      <td>9D4LK7X4LZ</td>\n",
       "      <td>D23PCWSM6S</td>\n",
       "      <td>36IIMAQD58</td>\n",
       "      <td>NN04B3F6UQ</td>\n",
       "      <td>JZP8MIJTPZ</td>\n",
       "      <td>B3EH2ZGQAV</td>\n",
       "      <td>1WZB1TE1HL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>448</td>\n",
       "      <td>Studio 8\\nMoss mall\\nWest Linda\\nM0E 6XR, High...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-EEA7AE62</td>\n",
       "      <td>33</td>\n",
       "      <td>1998-05-14</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>449</td>\n",
       "      <td>Baumplatz 6\\n80114 Kötzting, Bretten</td>\n",
       "      <td>49.03685</td>\n",
       "      <td>None</td>\n",
       "      <td>Bretten</td>\n",
       "      <td>BR-662EC74C</td>\n",
       "      <td>35</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>Local</td>\n",
       "      <td>8.70745</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>Gotthilf-Rose-Straße 7/3\\n45457 Feuchtwangen, ...</td>\n",
       "      <td>50.64336</td>\n",
       "      <td>None</td>\n",
       "      <td>Bad Honnef</td>\n",
       "      <td>BA-B4AED588</td>\n",
       "      <td>36</td>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>Local</td>\n",
       "      <td>7.2278</td>\n",
       "      <td>DE</td>\n",
       "      <td>eeEurope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                            address   longitude  \\\n",
       "0        0                                                N/A         N/A   \n",
       "1        1  Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...    51.62907   \n",
       "2        2        Heckerstraße 4/5\\n50491 Säckingen, Landshut    48.52961   \n",
       "3        3  5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury       51.26   \n",
       "4        4  Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...     53.0233   \n",
       "..     ...                                                ...         ...   \n",
       "446    446    Täschestraße 25\\n39039 Nördlingen, Kirchlengern        52.2   \n",
       "447    447                                         K0ODETRLS3  K8CXLZDP07   \n",
       "448    448  Studio 8\\nMoss mall\\nWest Linda\\nM0E 6XR, High...    51.62907   \n",
       "449    449               Baumplatz 6\\n80114 Kötzting, Bretten    49.03685   \n",
       "450    450  Gotthilf-Rose-Straße 7/3\\n45457 Feuchtwangen, ...    50.64336   \n",
       "\n",
       "            lat      locality    store_code staff_numbers opening_date  \\\n",
       "0           N/A           N/A  WEB-1388012W           325   2010-06-12   \n",
       "1          None  High Wycombe   HI-9B97EE4E            34   1996-10-25   \n",
       "2          None      Landshut   LA-0772C7B9            92   2013-04-12   \n",
       "3          None      Westbury   WE-1DE82CEE            69   2014-01-02   \n",
       "4          None        Belper   BE-18074576            35   2019-09-09   \n",
       "..          ...           ...           ...           ...          ...   \n",
       "446        None  Kirchlengern   KI-78096E8C            61   2005-05-12   \n",
       "447  UXMWDMX1LC    3VHFDNP8ET    9D4LK7X4LZ    D23PCWSM6S   36IIMAQD58   \n",
       "448        None  High Wycombe   HI-EEA7AE62            33   1998-05-14   \n",
       "449        None       Bretten   BR-662EC74C            35   2020-10-17   \n",
       "450        None    Bad Honnef   BA-B4AED588            36   2001-05-12   \n",
       "\n",
       "      store_type    latitude country_code   continent  \n",
       "0     Web Portal        None           GB      Europe  \n",
       "1          Local    -0.74934           GB      Europe  \n",
       "2    Super Store    12.16179           DE      Europe  \n",
       "3    Super Store     -2.1875           GB      Europe  \n",
       "4          Local    -1.48119           GB      Europe  \n",
       "..           ...         ...          ...         ...  \n",
       "446  Super Store     8.63333           DE      Europe  \n",
       "447   NN04B3F6UQ  JZP8MIJTPZ   B3EH2ZGQAV  1WZB1TE1HL  \n",
       "448        Local    -0.74934           GB      Europe  \n",
       "449        Local     8.70745           DE      Europe  \n",
       "450        Local      7.2278           DE    eeEurope  \n",
       "\n",
       "[451 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started cleaning_store_details\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>325</td>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>None</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.18750</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            address longitude   lat  \\\n",
       "0      0                                                N/A       N/A   N/A   \n",
       "1      1  Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...  51.62907  None   \n",
       "2      2        Heckerstraße 4/5\\n50491 Säckingen, Landshut  48.52961  None   \n",
       "3      3  5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury     51.26  None   \n",
       "\n",
       "       locality    store_code staff_numbers opening_date   store_type  \\\n",
       "0           N/A  WEB-1388012W           325   2010-06-12   Web Portal   \n",
       "1  High Wycombe   HI-9B97EE4E            34   1996-10-25        Local   \n",
       "2      Landshut   LA-0772C7B9            92   2013-04-12  Super Store   \n",
       "3      Westbury   WE-1DE82CEE            69   2014-01-02  Super Store   \n",
       "\n",
       "   latitude country_code continent  \n",
       "0       NaN           GB    Europe  \n",
       "1  -0.74934           GB    Europe  \n",
       "2  12.16179           DE    Europe  \n",
       "3  -2.18750           GB    Europe  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.18750</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            address longitude  \\\n",
       "1      1  Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...  51.62907   \n",
       "2      2        Heckerstraße 4/5\\n50491 Säckingen, Landshut  48.52961   \n",
       "3      3  5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury     51.26   \n",
       "4      4  Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...   53.0233   \n",
       "\n",
       "       locality   store_code staff_numbers opening_date   store_type  \\\n",
       "1  High Wycombe  HI-9B97EE4E            34   1996-10-25        Local   \n",
       "2      Landshut  LA-0772C7B9            92   2013-04-12  Super Store   \n",
       "3      Westbury  WE-1DE82CEE            69   2014-01-02  Super Store   \n",
       "4        Belper  BE-18074576            35   2019-09-09        Local   \n",
       "\n",
       "   latitude country_code continent  \n",
       "1  -0.74934           GB    Europe  \n",
       "2  12.16179           DE    Europe  \n",
       "3  -2.18750           GB    Europe  \n",
       "4  -1.48119           GB    Europe  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'last'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.18750</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            address longitude  \\\n",
       "1      1  Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...  51.62907   \n",
       "2      2        Heckerstraße 4/5\\n50491 Säckingen, Landshut  48.52961   \n",
       "3      3  5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury     51.26   \n",
       "4      4  Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...   53.0233   \n",
       "\n",
       "       locality   store_code staff_numbers opening_date   store_type  \\\n",
       "1  High Wycombe  HI-9B97EE4E            34   1996-10-25        Local   \n",
       "2      Landshut  LA-0772C7B9            92   2013-04-12  Super Store   \n",
       "3      Westbury  WE-1DE82CEE            69   2014-01-02  Super Store   \n",
       "4        Belper  BE-18074576            35   2019-09-09        Local   \n",
       "\n",
       "   latitude country_code continent  \n",
       "1  -0.74934           GB    Europe  \n",
       "2  12.16179           DE    Europe  \n",
       "3  -2.18750           GB    Europe  \n",
       "4  -1.48119           GB    Europe  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 428 entries, 1 to 450\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   index          428 non-null    int64         \n",
      " 1   address        428 non-null    object        \n",
      " 2   longitude      428 non-null    object        \n",
      " 3   locality       428 non-null    object        \n",
      " 4   store_code     428 non-null    object        \n",
      " 5   staff_numbers  428 non-null    object        \n",
      " 6   opening_date   428 non-null    datetime64[ns]\n",
      " 7   store_type     428 non-null    object        \n",
      " 8   latitude       428 non-null    float64       \n",
      " 9   country_code   428 non-null    object        \n",
      " 10  continent      428 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(8)\n",
      "memory usage: 40.1+ KB\n",
      "upload_to_db is working\n",
      "init_my_db_engine is working\n",
      "read_my_db_creds is working\n",
      "Connection to the PostgreSQL database was successful!\n",
      "Table 'dim_store_details' uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from database_utils import DatabaseConnector\n",
    "\n",
    "# LOGGING \n",
    "print('Started cleaning_store_details')\n",
    "\n",
    "#retrieving the data from the stores API\n",
    "df = raw_df\n",
    "\n",
    "display(df.head(4)) \n",
    "\n",
    "# Clean the latitude column\n",
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "df = df.dropna(subset=['latitude'])\n",
    "\n",
    "# Dropping the 'latitude' column as it's empty \n",
    "df = df.drop(columns=['lat'])\n",
    "\n",
    "# filtering out items in locality that aren't real place names or NULL \n",
    "pattern = r'^[a-zA-Z\\s-]+$'\n",
    "df = df[df['locality'].str.match(pattern)]\n",
    "df['locality'] = df['locality'].replace('NULL', np.nan)\n",
    "df = df.dropna(subset=['locality'])\n",
    "\n",
    "display(df.head(4))  \n",
    "\n",
    "# replacing incorrect spellings of continents \n",
    "continent_replacements = {\n",
    "    'eeEurope': 'Europe',\n",
    "    'eeAmerica': 'America'\n",
    "}\n",
    "\n",
    "df['continent'] = df['continent'].replace(continent_replacements)\n",
    "\n",
    "# LOGGING: checking everything has worked \n",
    "#print(df['continent'].unique())\n",
    "#print(df['store_type'].unique()) \n",
    "#print(df['country_code'].unique()) \n",
    "#print(df['continent'].unique())\n",
    "\n",
    "# LOGGING: checking of datetime before is datetime64 datetype  \n",
    "#is_datetime_before = pd.api.types.is_datetime64_any_dtype(df['opening_date'])\n",
    "\n",
    "# converting opening date to datetime object \n",
    "df['opening_date'] = pd.to_datetime(df['opening_date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# dropping any rows which contain missing values  \n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# Filter the DataFrame to keep only rows where 'latitude' is not NaN\n",
    "non_null_rows = df[df['opening_date'].isna()]  \n",
    "\n",
    "# Convert the filtered DataFrame to a list of rows\n",
    "non_null_list = non_null_rows.values.tolist()\n",
    "\n",
    "display(len(non_null_list))\n",
    "display(non_null_list)\n",
    "# LOGGING: checking the conversion worked \n",
    "#is_datetime_after = pd.api.types.is_datetime64_any_dtype(df['opening_date'])\n",
    "#print(f\"Is 'dates' column datetime64 dtype? {is_datetime_before}\")\n",
    "#print(f\"Is 'dates' column datetime64 dtype? {is_datetime_after}\")\n",
    "display('last', df.head(4)) \n",
    "#returning the dataframe \n",
    "df.info()  \n",
    "\n",
    "databaseconnector_instance = DatabaseConnector() \n",
    "\n",
    "databaseconnector_instance.upload_to_db(df, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ignore below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKUP OF CHATGPT UUID CODE WITH CHECKS \n",
    "\n",
    "# Function to run all operations\n",
    "def run_all_operations():\n",
    "    \n",
    "    # Create instance of a DatabaseConnector  \n",
    "    instance = DatabaseConnector() \n",
    "    # Create an engine by using the init_my_db_engine() method of DatabaseConnector \n",
    "    engine = instance.init_my_db_engine()\n",
    "    \n",
    "    #try to do engine.connect() \n",
    "    with engine.connect() as connection:\n",
    "        \n",
    "        # Fetch and print data before conversion\n",
    "        print(\"Data before conversion:\")\n",
    "        data_before = fetch_data(connection, 'orders_table')\n",
    "        for row in data_before:\n",
    "            print(row)\n",
    "        \n",
    "        # Check and print column type before conversion\n",
    "        column_type_before = check_column_type(connection, 'orders_table', 'date_uuid')\n",
    "        print(f\"Column type before conversion: {column_type_before}\")\n",
    "        \n",
    "        #put the attempt to run the functions in a try block \n",
    "        try:\n",
    "            clean_uuid(connection, 'orders_table', 'date_uuid')\n",
    "            print('Clean UUID worked')\n",
    "            convert_data_uuid(connection, 'orders_table', 'date_uuid')\n",
    "            print('Convert to UUID worked')\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "        # Fetch and print data after conversion\n",
    "        print(\"Data after conversion:\")\n",
    "        data_after = fetch_data(connection, 'orders_table')\n",
    "        for row in data_after:\n",
    "            print(row)\n",
    "        \n",
    "        # Check and print column type after conversion\n",
    "        column_type_after = check_column_type(connection, 'orders_table', 'date_uuid')\n",
    "        print(f\"Column type after conversion: {column_type_after}\")\n",
    "\n",
    "    print('End of call')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THINK THIS CAN BE GOTTEN RID OF \n",
    "#def cast_data(): \n",
    "  \n",
    "#UUID \n",
    "# Create function to clean uuid with regex \n",
    "def clean_uuid(connection, table_name, column_name):\n",
    "    clean_uuid = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET {column_name} = NULL\n",
    "        WHERE {column_name} !~ '^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$';\n",
    "        \"\"\"  \n",
    "    # Convert the SQL string to a TextClause object and execute the query\n",
    "    connection.execute(text(clean_uuid))\n",
    "\n",
    "# Create function to update specified column to UUID \n",
    "def convert_data_uuid(connection, table_name, column_name): \n",
    "    convert_date_uuid = f\"\"\"\n",
    "        ALTER TABLE {table_name}\n",
    "        ALTER COLUMN {column_name} TYPE UUID\n",
    "        USING {column_name}::UUID;\n",
    "        \"\"\"\n",
    "    # Convert the SQL string to a TextClause object and execute the query\n",
    "    connection.execute(text(convert_date_uuid))\n",
    "\n",
    "# Function to run all operations\n",
    "def run_all_operations():\n",
    "    \n",
    "    # Create instance of a DatabaseConnector  \n",
    "    instance = DatabaseConnector() \n",
    "    # Create an engine by using the init_my_db_engine() method of DatabaseConnector \n",
    "    engine = instance.init_my_db_engine()\n",
    "    \n",
    "    #try to do engine.connect() \n",
    "    with engine.connect() as connection:\n",
    "        \n",
    "        #put the attempt to run the functions in a try block \n",
    "        try:\n",
    "            clean_uuid(connection, 'orders_table', 'date_uuid')\n",
    "            print('clean uuid worked')\n",
    "            #max_length = get_max_length(connection, table_name, column_name)\n",
    "            #convert_numbers(connection, table_name, column_name, max_length)\n",
    "            #print(\"Data cleaning and conversion completed successfully.\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print('end of call')\n",
    "run_all_operations() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE GET RID OF \n",
    "# Function to run all operations\n",
    "def run_all_operations():\n",
    "    \n",
    "    # Create instance of a DatabaseConnector  \n",
    "    instance = DatabaseConnector() \n",
    "    # Create an engine by using the init_my_db_engine() method of DatabaseConnector \n",
    "    engine = instance.init_my_db_engine()\n",
    "    \n",
    "    #try to do engine.connect() \n",
    "    with engine.connect() as connection:\n",
    "        \n",
    "        # Fetch and print data before conversion\n",
    "        print(\"Data before conversion:\")\n",
    "        data_before = fetch_data(connection, 'orders_table')\n",
    "        #data_before returns a list of tuples, each tuple is a row in the database, the list is all the rows \n",
    "        for row in data_before:\n",
    "            print(row)\n",
    "        \n",
    "        # Check and print column type before conversion\n",
    "        column_type_before = check_column_type(connection, 'orders_table', 'date_uuid')\n",
    "        print(f\"Column type before conversion: {column_type_before}\")\n",
    "        \n",
    "        #put the attempt to run the functions in a try block \n",
    "        try:\n",
    "            clean_uuid(connection, 'orders_table', 'date_uuid')\n",
    "            print('Clean UUID worked')\n",
    "            convert_data_uuid(connection, 'orders_table', 'date_uuid')\n",
    "            print('Convert to UUID worked')\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "        # Fetch and print data after conversion\n",
    "        print(\"Data after conversion:\")\n",
    "        data_after = fetch_data(connection, 'orders_table')\n",
    "        for row in data_after:\n",
    "            print(row)\n",
    "        \n",
    "        # Check and print column type after conversion\n",
    "        column_type_after = check_column_type(connection, 'orders_table', 'date_uuid')\n",
    "        print(f\"Column type after conversion: {column_type_after}\")\n",
    "\n",
    "    print('End of call')\n",
    "\n",
    "run_all_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE\n",
    "\n",
    "#THIS WILL BE THE FUNCTION THAT RUNS ALL THE OTHER SUBFUNCTIONS. BUT NEED TO DECIDE IF IT\"S EASIER TO PUT IT IN CLASS ('CASTING') WITH EACH SUB FUNCTION AS A METHOD\n",
    "\n",
    "class DataCasting:\n",
    "\n",
    "    def __init__(self):\n",
    "        #connection = XXXX \n",
    "    \n",
    "def cast_data(): \n",
    "    \n",
    "    # Create instance of a DatabaseConnector  \n",
    "    instance = DatabaseConnector() \n",
    "\n",
    "    # Create an engine by using the init_my_db_engine() method of DatabaseConnector \n",
    "    engine = instance.init_my_db_engine()\n",
    "\n",
    "    with engine.connect() as connection:    \n",
    "#THIS IS WHERE I'M TRYING TO BUILD REUSABLE FUNCTIONS FOR EACH OF THE CAST TYPES AND APPLYING THEM \n",
    "\n",
    "\n",
    "#UUID \n",
    "    # Create function to clean uuid with regex \n",
    "    def clean_uuid(connection, table_name, column_name):\n",
    "        clean_uuid = f\"\"\"\n",
    "            UPDATE {table_name}\n",
    "            SET {column_name} = NULL\n",
    "            WHERE {column_name} !~ '^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$';\n",
    "            \"\"\"  \n",
    "        connection.execute(text(clean_uuid))\n",
    "\n",
    "    def convert_data_uuid(connection, table_name, column_name): \n",
    "        convert_date_uuid = f\"\"\"\n",
    "            ALTER TABLE {table_name}\n",
    "            ALTER COLUMN {column_name} TYPE UUID\n",
    "            USING {column_name}::UUID;\n",
    "            \"\"\"\n",
    "        # Convert the SQL string to a TextClause object and execute the query\n",
    "        connection.execute(text(convert_date_uuid))\n",
    "\n",
    "#VARCHAR \n",
    "\n",
    "    # Create function to clean card number data with regex\n",
    "    def clean_numbers(connection, table_name, column_name):\n",
    "        clean_numbers_sql = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET {column_name} = NULL\n",
    "        WHERE {column_name} !~ '^[0-9]+$';\n",
    "        \"\"\"  \n",
    "        connection.execute(text(clean_numbers_sql))\n",
    "\n",
    "    # Function to determine the maximum length of values in the column\n",
    "    def get_max_length(connection, table_name, column_name):\n",
    "        max_length_sql = f\"\"\"\n",
    "        SELECT MAX(LENGTH({column_name})) \n",
    "        FROM {table_name};\n",
    "        \"\"\"\n",
    "        result = connection.execute(text(max_length_sql)).fetchone()\n",
    "        return result[0]\n",
    "\n",
    "    # Function to convert the column to VARCHAR with the determined maximum length\n",
    "    def convert_numbers(connection, table_name, column_name, max_length): \n",
    "        convert_numbers_sql = f\"\"\"\n",
    "        ALTER TABLE {table_name}\n",
    "        ALTER COLUMN {column_name} TYPE VARCHAR({max_length})\n",
    "        USING {column_name}::VARCHAR({max_length});\n",
    "        \"\"\"\n",
    "        connection.execute(text(convert_numbers_sql))\n",
    "\n",
    "    # Function to run all operations\n",
    "    def run_all_operations(conn_string, table_name, column_name):\n",
    "        engine = create_engine(conn_string)\n",
    "        with engine.connect() as connection:\n",
    "            try:\n",
    "                clean_numbers(connection, table_name, column_name)\n",
    "                max_length = get_max_length(connection, table_name, column_name)\n",
    "                convert_numbers(connection, table_name, column_name, max_length)\n",
    "                print(\"Data cleaning and conversion completed successfully.\")\n",
    "            except SQLAlchemyError as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "#SMALL INT \n",
    "\n",
    "\n",
    "\n",
    "#THESE ARE SAMPLES FROM THE CHAT GPT CODE \n",
    "    def cast_column_to_integer(connection, table_name, column_name):\n",
    "        sql = f\"\"\"\n",
    "        ALTER TABLE {table_name}\n",
    "        ALTER COLUMN {column_name} TYPE INTEGER\n",
    "        USING {column_name}::INTEGER;\n",
    "        \"\"\"\n",
    "        connection.execute(text(sql))\n",
    "\n",
    "    def cast_column_to_date(connection, table_name, column_name):\n",
    "        sql = f\"\"\"\n",
    "        ALTER TABLE {table_name}\n",
    "        ALTER COLUMN {column_name} TYPE DATE\n",
    "        USING {column_name}::DATE;\n",
    "        \"\"\"\n",
    "        connection.execute(text(sql))\n",
    "\n",
    "#THIS IS MY ORIGINAL CODE THAT WORKED, BUT I REALISED IT WILL GET VERY LONG IF I DO ALL THE CASTING AND APPLYING FOR EVERY COLUMN \n",
    "\n",
    "    # Use a context manager to handle the connection\n",
    "    with engine.connect() as connection:  \n",
    "        try:\n",
    "            # Define the SQL query to clean data\n",
    "            clean_date_uuid = \"\"\"\n",
    "            UPDATE orders_table\n",
    "            SET date_uuid = NULL\n",
    "            WHERE date_uuid !~ '^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$';\n",
    "            \"\"\"  \n",
    "            \n",
    "            # Convert the SQL string to a TextClause object\n",
    "            clean_date_query = text(clean_date_uuid)\n",
    "            \n",
    "            # Execute the query\n",
    "            connection.execute(clean_date_query)\n",
    "\n",
    "            # Define the SQL query to alter the column data type\n",
    "            convert_date_uuid = \"\"\"\n",
    "            ALTER TABLE orders_table\n",
    "            ALTER COLUMN date_uuid TYPE UUID\n",
    "            USING date_uuid::UUID;\n",
    "            \"\"\"\n",
    "            # Convert the SQL string to a TextClause object\n",
    "            convert_date_query = text(convert_date_uuid)\n",
    "            \n",
    "            # Execute the query\n",
    "            connection.execute(convert_date_query)\n",
    "\n",
    "            print(\"Data type casting completed successfully.\")\n",
    "       \n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE \n",
    "# THIS IS THE CHATGPT CODE THAT I AM TAKING BITS FROM - IT'S GOT IDEAS FOR CREATING REUSABLE FUNCTIONS FOR EACH OF THE TYPES OF CASTING I NEED TO DO \n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "def cast_column_to_integer(connection, table_name, column_name):\n",
    "    sql = f\"\"\"\n",
    "    ALTER TABLE {table_name}\n",
    "    ALTER COLUMN {column_name} TYPE INTEGER\n",
    "    USING {column_name}::INTEGER;\n",
    "    \"\"\"\n",
    "    connection.execute(text(sql))\n",
    "\n",
    "def cast_column_to_date(connection, table_name, column_name):\n",
    "    sql = f\"\"\"\n",
    "    ALTER TABLE {table_name}\n",
    "    ALTER COLUMN {column_name} TYPE DATE\n",
    "    USING {column_name}::DATE;\n",
    "    \"\"\"\n",
    "    connection.execute(text(sql))\n",
    "\n",
    "def cast_column_to_boolean(connection, table_name, column_name):\n",
    "    sql = f\"\"\"\n",
    "    ALTER TABLE {table_name}\n",
    "    ALTER COLUMN {column_name} TYPE BOOLEAN\n",
    "    USING {column_name}::BOOLEAN;\n",
    "    \"\"\"\n",
    "    connection.execute(text(sql))\n",
    "\n",
    "# Add more functions as needed for different types\n",
    "\n",
    "def run_all_casting_operations(conn_string):\n",
    "    engine = create_engine(conn_string)\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            cast_column_to_integer(connection, 'users', 'age')\n",
    "            cast_column_to_date(connection, 'users', 'birthdate')\n",
    "            cast_column_to_boolean(connection, 'users', 'is_active')\n",
    "            # Add more casting operations as needed\n",
    "            print(\"All casting operations completed successfully.\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn_string = 'postgresql://username:password@localhost:5432/mydatabase'\n",
    "    run_all_casting_operations(conn_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS OLD CODE THAT I PROBABLY WON'T USE \n",
    "def run_data_casting(conn_string):\n",
    "    \"\"\"\n",
    "    Connects to the PostgreSQL database and performs data type casting\n",
    "    on the 'age' column in the 'users' table.\n",
    "    \n",
    "    Args:\n",
    "    conn_string (str): The connection string for the PostgreSQL database.\n",
    "    \"\"\"\n",
    "    # Create an engine to connect to the database\n",
    "    engine = create_engine(conn_string)\n",
    "    \n",
    "    # Use a context manager to handle the connection\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            # Define the SQL query to clean data\n",
    "            clean_data_sql = \"\"\"\n",
    "            UPDATE users\n",
    "            SET age = NULL\n",
    "            WHERE age !~ '^[0-9]+$';\n",
    "            \"\"\"\n",
    "            # Convert the SQL string to a TextClause object\n",
    "            clean_data_query = text(clean_data_sql)\n",
    "            \n",
    "            # Execute the query\n",
    "            connection.execute(clean_data_query)\n",
    "\n",
    "            # Define the SQL query to alter the column data type\n",
    "            alter_column_sql = \"\"\"\n",
    "            ALTER TABLE users\n",
    "            ALTER COLUMN age TYPE INTEGER\n",
    "            USING age::INTEGER;\n",
    "            \"\"\"\n",
    "            # Convert the SQL string to a TextClause object\n",
    "            alter_column_query = text(alter_column_sql)\n",
    "            \n",
    "            # Execute the query\n",
    "            connection.execute(alter_column_query)\n",
    "\n",
    "            print(\"Data type casting completed successfully.\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #VARCHAR \n",
    "\n",
    "#     # Create function to clean card number data with regex\n",
    "#     def clean_numbers(connection, table_name, column_name):\n",
    "#         clean_numbers_sql = f\"\"\"\n",
    "#         UPDATE {table_name}\n",
    "#         SET {column_name} = NULL\n",
    "#         WHERE {column_name} !~ '^[0-9]+$';\n",
    "#         \"\"\"  \n",
    "#         connection.execute(text(clean_numbers_sql))\n",
    "\n",
    "#     # Function to determine the maximum length of values in the column\n",
    "#     def get_max_length(connection, table_name, column_name):\n",
    "#         max_length_sql = f\"\"\"\n",
    "#         SELECT MAX(LENGTH({column_name})) \n",
    "#         FROM {table_name};\n",
    "#         \"\"\"\n",
    "#         result = connection.execute(text(max_length_sql)).fetchone()\n",
    "#         return result[0]\n",
    "\n",
    "#     # Function to convert the column to VARCHAR with the determined maximum length\n",
    "#     def convert_numbers(connection, table_name, column_name, max_length): \n",
    "#         convert_numbers_sql = f\"\"\"\n",
    "#         ALTER TABLE {table_name}\n",
    "#         ALTER COLUMN {column_name} TYPE VARCHAR({max_length})\n",
    "#         USING {column_name}::VARCHAR({max_length});\n",
    "#         \"\"\"\n",
    "#         connection.execute(text(convert_numbers_sql))\n",
    "\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinational_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
