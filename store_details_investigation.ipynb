{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging \n",
    "import numpy as np\n",
    "import re \n",
    "from IPython.display import display\n",
    "from sqlalchemy import MetaData, Table\n",
    "from database_utils import DatabaseConnector\n",
    "from data_extraction import DataExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 31 july \n",
    "# try to get to the bottom of the latitide thing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started cleaning_store_details\n",
      "retrieve_stores_data is working\n",
      "read_api_key is working\n",
      "read_api_key is done\n",
      "Skipped Stores DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# LOGGING \n",
    "print('Started cleaning_store_details')\n",
    "\n",
    "#creating instance of dataextractor \n",
    "instance = DataExtractor()\n",
    "\n",
    "#retrieving the data from the stores API - this takes around 90 seconds \n",
    "df = instance.retrieve_stores_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a back up of the dataframe \n",
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to reset the df \n",
    "df = df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 451 entries, 0 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          451 non-null    int64 \n",
      " 1   address        451 non-null    object\n",
      " 2   longitude      451 non-null    object\n",
      " 3   lat            11 non-null     object\n",
      " 4   locality       451 non-null    object\n",
      " 5   store_code     451 non-null    object\n",
      " 6   staff_numbers  451 non-null    object\n",
      " 7   opening_date   451 non-null    object\n",
      " 8   store_type     451 non-null    object\n",
      " 9   latitude       450 non-null    object\n",
      " 10  country_code   451 non-null    object\n",
      " 11  continent      451 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 42.4+ KB\n",
      "Number of rows store data before cleaning: 451\n",
      "Number of rows store data after cleaning latitide column: 440\n",
      "Number of rows store data after dropping lat column: 440\n",
      "Number of rows store data after cleaning locality: 440\n",
      "Number of rows store data after cleaning continent: 440\n",
      "Number of rows store data after cleaning opening date: 428\n",
      "Number of rows store data after cleaning: 428\n"
     ]
    }
   ],
   "source": [
    "# code to clean the dataframe \n",
    "# Number of rows store data before cleaning: 451\n",
    "# Number of rows store data after dropping lat and cleaning latitide column: 440\n",
    "# Number of rows store data after cleaning locality: 440\n",
    "# Number of rows store data after cleaning continent: 440\n",
    "# Number of rows store data after cleaning opening date: 428\n",
    "# Number of rows store data after cleaning: 428\n",
    "\n",
    "df.info()\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data before cleaning: {num_rows}\")\n",
    "\n",
    "# Clean the latitude column\n",
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "df = df.dropna(subset=['latitude'])\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning latitide column: {num_rows}\")\n",
    "\n",
    "# Dropping the 'latitude' column as it's empty \n",
    "df = df.drop(columns=['lat'])\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after dropping lat column: {num_rows}\")\n",
    "\n",
    "# filtering out items in locality that aren't real place names or NULL \n",
    "pattern = r'^[a-zA-Z\\s-]+$'\n",
    "df = df[df['locality'].str.match(pattern)]\n",
    "df['locality'] = df['locality'].replace('NULL', np.nan)\n",
    "df = df.dropna(subset=['locality'])\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning locality: {num_rows}\")\n",
    "\n",
    "# replacing incorrect spellings of continents \n",
    "continent_replacements = {\n",
    "    'eeEurope': 'Europe',\n",
    "    'eeAmerica': 'America'\n",
    "}\n",
    "\n",
    "df['continent'] = df['continent'].replace(continent_replacements)\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning continent: {num_rows}\")\n",
    "\n",
    "# LOGGING: checking everything has worked \n",
    "#print(df['continent'].unique())\n",
    "#print(df['store_type'].unique()) \n",
    "#print(df['country_code'].unique()) \n",
    "#print(df['continent'].unique())\n",
    "\n",
    "# LOGGING: checking of datetime before is datetime64 datetype  \n",
    "#is_datetime_before = pd.api.types.is_datetime64_any_dtype(df['opening_date'])\n",
    "\n",
    "# converting opening date to datetime object \n",
    "df['opening_date'] = pd.to_datetime(df['opening_date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# dropping any rows which contain missing values  \n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning opening date: {num_rows}\")\n",
    "\n",
    "# LOGGING: checking the conversion worked \n",
    "#is_datetime_after = pd.api.types.is_datetime64_any_dtype(df['opening_date'])\n",
    "#print(f\"Is 'dates' column datetime64 dtype? {is_datetime_before}\")\n",
    "#print(f\"Is 'dates' column datetime64 dtype? {is_datetime_after}\")\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning: {num_rows}\")\n",
    "#returning the dataframe \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinational_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
