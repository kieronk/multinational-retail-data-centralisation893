{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging \n",
    "import numpy as np\n",
    "import re \n",
    "from IPython.display import display\n",
    "from sqlalchemy import MetaData, Table\n",
    "from database_utils import DatabaseConnector\n",
    "from data_extraction import DataExtractor\n",
    "from unidecode import unidecode\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 31 july \n",
    "# try to get to the bottom of the 'lat' thing, I have a list of 10 but am confused about how to take them out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started cleaning_store_details\n",
      "retrieve_stores_data is working\n",
      "read_api_key is working\n",
      "read_api_key is done\n",
      "Skipped Stores DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# LOGGING \n",
    "print('Started cleaning_store_details')\n",
    "\n",
    "#creating instance of dataextractor \n",
    "instance = DataExtractor()\n",
    "\n",
    "#retrieving the data from the stores API - this takes around 90 seconds \n",
    "df = instance.retrieve_stores_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a back up of the dataframe \n",
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to reset the df \n",
    "df = df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows store data before cleaning: 451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>6FWDZHD7PW</td>\n",
       "      <td>1ZVU03X2P6</td>\n",
       "      <td>13KJZ890JH</td>\n",
       "      <td>9IBH8Y4Z0S</td>\n",
       "      <td>NRQKZWJ9OZ</td>\n",
       "      <td>BIP8K8JJW2</td>\n",
       "      <td>ZCXWWKF45G</td>\n",
       "      <td>QP74AHEQT0</td>\n",
       "      <td>1CJ5OAU4BR</td>\n",
       "      <td>YELVM536YT</td>\n",
       "      <td>QMAVR5H3LD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>UBCIFQLSNY</td>\n",
       "      <td>Q1TJY8H1ZH</td>\n",
       "      <td>2XE1OWOC23</td>\n",
       "      <td>1T6B406CI8</td>\n",
       "      <td>QIUU9SVP51</td>\n",
       "      <td>SKBXAXF5G5</td>\n",
       "      <td>7AHXLXIUEF</td>\n",
       "      <td>O0QJIRC943</td>\n",
       "      <td>3ZR3F89D97</td>\n",
       "      <td>FP8DLXQVGH</td>\n",
       "      <td>LU3E036ZD9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>RC99UKMZB2</td>\n",
       "      <td>2YBZ1440V6</td>\n",
       "      <td>OXVE5QR07O</td>\n",
       "      <td>6LVWPU1G64</td>\n",
       "      <td>Y8J0Z2W8O9</td>\n",
       "      <td>2429OB3LMM</td>\n",
       "      <td>0OLAK2I6NS</td>\n",
       "      <td>50IB01SFAZ</td>\n",
       "      <td>L13EQEQODP</td>\n",
       "      <td>HMHIFNLOBN</td>\n",
       "      <td>5586JCLARW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>333</td>\n",
       "      <td>X349GIDWKU</td>\n",
       "      <td>O7NF1FZ74Y</td>\n",
       "      <td>VKA5I8H32X</td>\n",
       "      <td>RX9TCP2RGB</td>\n",
       "      <td>ISEE8A57FE</td>\n",
       "      <td>74BY7HSB6P</td>\n",
       "      <td>A3PMVM800J</td>\n",
       "      <td>0RSNUU3DF5</td>\n",
       "      <td>J3BPB68Z1J</td>\n",
       "      <td>F3AO8V2LHU</td>\n",
       "      <td>GFJQ2AAEQ8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>381</td>\n",
       "      <td>ZBGB54ID4H</td>\n",
       "      <td>SKO4NMRNNF</td>\n",
       "      <td>LACCWDI0SB</td>\n",
       "      <td>CQMHKI78BX</td>\n",
       "      <td>T0R2CQBDUS</td>\n",
       "      <td>GT1FO6YGD4</td>\n",
       "      <td>GMMB02LA9V</td>\n",
       "      <td>B4KVQB3P5Y</td>\n",
       "      <td>AJHOMDOHZ4</td>\n",
       "      <td>OH20I92LX3</td>\n",
       "      <td>SLQBD982C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>XTUAV57DP4</td>\n",
       "      <td>ID819KG3X5</td>\n",
       "      <td>A3O5CBWAMD</td>\n",
       "      <td>RY6K0AUE7F</td>\n",
       "      <td>TUOKF5HAAQ</td>\n",
       "      <td>FRTGHAA34B</td>\n",
       "      <td>13PIY8GD1H</td>\n",
       "      <td>X0FE7E2EOG</td>\n",
       "      <td>AE7EEW4HSS</td>\n",
       "      <td>OYVW925ZL8</td>\n",
       "      <td>XQ953VS0FG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>447</td>\n",
       "      <td>K0ODETRLS3</td>\n",
       "      <td>K8CXLZDP07</td>\n",
       "      <td>UXMWDMX1LC</td>\n",
       "      <td>3VHFDNP8ET</td>\n",
       "      <td>9D4LK7X4LZ</td>\n",
       "      <td>D23PCWSM6S</td>\n",
       "      <td>36IIMAQD58</td>\n",
       "      <td>NN04B3F6UQ</td>\n",
       "      <td>JZP8MIJTPZ</td>\n",
       "      <td>B3EH2ZGQAV</td>\n",
       "      <td>1WZB1TE1HL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index     address   longitude         lat    locality  store_code  \\\n",
       "63      63  6FWDZHD7PW  1ZVU03X2P6  13KJZ890JH  9IBH8Y4Z0S  NRQKZWJ9OZ   \n",
       "172    172  UBCIFQLSNY  Q1TJY8H1ZH  2XE1OWOC23  1T6B406CI8  QIUU9SVP51   \n",
       "217    217        NULL        NULL        NULL        NULL        NULL   \n",
       "231    231  RC99UKMZB2  2YBZ1440V6  OXVE5QR07O  6LVWPU1G64  Y8J0Z2W8O9   \n",
       "333    333  X349GIDWKU  O7NF1FZ74Y  VKA5I8H32X  RX9TCP2RGB  ISEE8A57FE   \n",
       "381    381  ZBGB54ID4H  SKO4NMRNNF  LACCWDI0SB  CQMHKI78BX  T0R2CQBDUS   \n",
       "405    405        NULL        NULL        NULL        NULL        NULL   \n",
       "414    414  XTUAV57DP4  ID819KG3X5  A3O5CBWAMD  RY6K0AUE7F  TUOKF5HAAQ   \n",
       "437    437        NULL        NULL        NULL        NULL        NULL   \n",
       "447    447  K0ODETRLS3  K8CXLZDP07  UXMWDMX1LC  3VHFDNP8ET  9D4LK7X4LZ   \n",
       "\n",
       "    staff_numbers opening_date  store_type    latitude country_code  \\\n",
       "63     BIP8K8JJW2   ZCXWWKF45G  QP74AHEQT0  1CJ5OAU4BR   YELVM536YT   \n",
       "172    SKBXAXF5G5   7AHXLXIUEF  O0QJIRC943  3ZR3F89D97   FP8DLXQVGH   \n",
       "217          NULL         NULL        NULL        NULL         NULL   \n",
       "231    2429OB3LMM   0OLAK2I6NS  50IB01SFAZ  L13EQEQODP   HMHIFNLOBN   \n",
       "333    74BY7HSB6P   A3PMVM800J  0RSNUU3DF5  J3BPB68Z1J   F3AO8V2LHU   \n",
       "381    GT1FO6YGD4   GMMB02LA9V  B4KVQB3P5Y  AJHOMDOHZ4   OH20I92LX3   \n",
       "405          NULL         NULL        NULL        NULL         NULL   \n",
       "414    FRTGHAA34B   13PIY8GD1H  X0FE7E2EOG  AE7EEW4HSS   OYVW925ZL8   \n",
       "437          NULL         NULL        NULL        NULL         NULL   \n",
       "447    D23PCWSM6S   36IIMAQD58  NN04B3F6UQ  JZP8MIJTPZ   B3EH2ZGQAV   \n",
       "\n",
       "      continent  \n",
       "63   QMAVR5H3LD  \n",
       "172  LU3E036ZD9  \n",
       "217        NULL  \n",
       "231  5586JCLARW  \n",
       "333  GFJQ2AAEQ8  \n",
       "381  SLQBD982C0  \n",
       "405        NULL  \n",
       "414  XQ953VS0FG  \n",
       "437        NULL  \n",
       "447  1WZB1TE1HL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows store data after dropping lat column: 441\n",
      "Rows that will be converted to 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Flat 69\\nSuzanne walk\\nEast Michelle\\nE80 8HS,...</td>\n",
       "      <td>52.68333</td>\n",
       "      <td>None</td>\n",
       "      <td>East Dereham</td>\n",
       "      <td>EA-24B31935</td>\n",
       "      <td>J78</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>Outlet</td>\n",
       "      <td>0.93333</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>Girschnerweg 163\\n93597 Angermünde, Dahlem</td>\n",
       "      <td>52.4581</td>\n",
       "      <td>None</td>\n",
       "      <td>Dahlem</td>\n",
       "      <td>DA-ACC520AE</td>\n",
       "      <td>30e</td>\n",
       "      <td>1994-03-07</td>\n",
       "      <td>Local</td>\n",
       "      <td>13.28702</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>7430 Howe Extensions Suite 299\\nKellyside, WA ...</td>\n",
       "      <td>39.71734</td>\n",
       "      <td>None</td>\n",
       "      <td>Sicklerville</td>\n",
       "      <td>SI-C489938D</td>\n",
       "      <td>80R</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>Outlet</td>\n",
       "      <td>-74.96933</td>\n",
       "      <td>US</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>341</td>\n",
       "      <td>Studio 8\\nLydia groves\\nNorth Hilarymouth\\nIV4...</td>\n",
       "      <td>50.79205</td>\n",
       "      <td>None</td>\n",
       "      <td>Southsea</td>\n",
       "      <td>SO-B5B9CB3B</td>\n",
       "      <td>A97</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-1.08593</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>Salzstraße 1/9\\n74209 Bad Freienwalde, Charlot...</td>\n",
       "      <td>52.53048</td>\n",
       "      <td>None</td>\n",
       "      <td>Charlottenburg-Nord</td>\n",
       "      <td>CH-99475026</td>\n",
       "      <td>3n9</td>\n",
       "      <td>1995-03-05</td>\n",
       "      <td>Local</td>\n",
       "      <td>13.29371</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                            address longitude   lat  \\\n",
       "31      31  Flat 69\\nSuzanne walk\\nEast Michelle\\nE80 8HS,...  52.68333  None   \n",
       "179    179         Girschnerweg 163\\n93597 Angermünde, Dahlem   52.4581  None   \n",
       "248    248  7430 Howe Extensions Suite 299\\nKellyside, WA ...  39.71734  None   \n",
       "341    341  Studio 8\\nLydia groves\\nNorth Hilarymouth\\nIV4...  50.79205  None   \n",
       "375    375  Salzstraße 1/9\\n74209 Bad Freienwalde, Charlot...  52.53048  None   \n",
       "\n",
       "                locality   store_code staff_numbers opening_date   store_type  \\\n",
       "31          East Dereham  EA-24B31935           J78   2012-11-09       Outlet   \n",
       "179               Dahlem  DA-ACC520AE           30e   1994-03-07        Local   \n",
       "248         Sicklerville  SI-C489938D           80R   1994-02-28       Outlet   \n",
       "341             Southsea  SO-B5B9CB3B           A97   2018-05-08  Super Store   \n",
       "375  Charlottenburg-Nord  CH-99475026           3n9   1995-03-05        Local   \n",
       "\n",
       "      latitude country_code continent  \n",
       "31     0.93333           GB    Europe  \n",
       "179   13.28702           DE    Europe  \n",
       "248  -74.96933           US   America  \n",
       "341   -1.08593           GB    Europe  \n",
       "375   13.29371           DE    Europe  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows store data after cleaning continent: 441\n",
      "Rows that will be dropped during locality cleaning:\n",
      "Empty DataFrame\n",
      "Columns: [index, address, longitude, lat, locality, store_code, staff_numbers, opening_date, store_type, latitude, country_code, continent]\n",
      "Index: []\n",
      "Number of rows store data after cleaning locality: 441\n",
      "Number of rows store data after cleaning: 441\n",
      "Number of rows before opening_date cleaning: 441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Rows that would be converted to NULL:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, address, longitude, lat, locality, store_code, staff_numbers, opening_date, store_type, latitude, country_code, continent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nList of invalid dates:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after opening_date cleaning: 441\n"
     ]
    }
   ],
   "source": [
    "df = df_backup.copy()\n",
    "\n",
    "\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data before cleaning: {num_rows}\")\n",
    "\n",
    "# STEP 1 make the webstore have prooper entries \n",
    "\n",
    "# logging \n",
    "# before = df.iloc[0]\n",
    "# display(before)\n",
    "\n",
    "# Define the index of the record to update\n",
    "index_to_update = 0\n",
    "\n",
    "# Define the values to replace 'N/A' with for the specific record\n",
    "df.loc[index_to_update, 'address'] = 'online'\n",
    "df.loc[index_to_update, 'longitude'] = 1\n",
    "df.loc[index_to_update, 'lat'] = 1\n",
    "df.loc[index_to_update, 'locality'] = 'online'\n",
    "df.loc[index_to_update, 'latitude'] = 1\n",
    "\n",
    "# logging\n",
    "# after = df.iloc[0]\n",
    "# display(after)\n",
    "\n",
    "\n",
    "# STEP 2 remove garbage records and NULL from lat \n",
    "\n",
    "# Define the regex pattern to match invalid lat values\n",
    "pattern = r'^[A-Za-z0-9]+$'\n",
    "\n",
    "# Create a boolean mask for rows to keep: rows that do not match the pattern and are not 'NULL'\n",
    "mask = ~df['lat'].str.contains(pattern, na=False) & ~df['lat'].isin(['NULL'])\n",
    "\n",
    "display(df[~mask])\n",
    "\n",
    "# Filter the DataFrame using the mask\n",
    "df = df[mask]\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after dropping lat column: {num_rows}\")\n",
    "\n",
    "#STEP 3 cleaning staff numbers\n",
    "\n",
    "# Define the regex pattern to match digits only\n",
    "pattern = r'^\\d+$'\n",
    "\n",
    "# Create a boolean mask for rows that are not digits\n",
    "mask = ~df['staff_numbers'].str.match(pattern, na=False)\n",
    "\n",
    "# Display the rows that will be converted to 0\n",
    "print(\"Rows that will be converted to 0:\")\n",
    "display(df[mask])\n",
    "\n",
    "# Convert non-digit values to 0\n",
    "df.loc[mask, 'staff_numbers'] = 0\n",
    "\n",
    "# Convert the staff_numbers column to integer\n",
    "df['staff_numbers'] = df['staff_numbers'].astype(int)\n",
    "\n",
    "# STEP 4, cleaning continents \n",
    "\n",
    "# replacing incorrect spellings of continents \n",
    "continent_replacements = {\n",
    "    'eeEurope': 'Europe',\n",
    "    'eeAmerica': 'America'\n",
    "}\n",
    "\n",
    "df['continent'] = df['continent'].replace(continent_replacements)\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning continent: {num_rows}\")\n",
    "\n",
    "# STEP 5, cleaning locality \n",
    "\n",
    "# filtering out items in locality that aren't real place names or NULL \n",
    "pattern = r'^[a-zA-Z\\s-]+$'\n",
    "locality_mask = df['locality'].str.match(pattern, na=False) | (df.index == 0)\n",
    "\n",
    "# Capture the rows that will be dropped\n",
    "rows_dropped_by_locality = df[~locality_mask | df['locality'].replace('NULL', np.nan).isna()]\n",
    "print(\"Rows that will be dropped during locality cleaning:\")\n",
    "print(rows_dropped_by_locality)\n",
    "\n",
    "# Apply the locality mask\n",
    "df = df[locality_mask]\n",
    "\n",
    "# Replace 'NULL' with np.nan and drop rows where 'locality' is NaN\n",
    "df['locality'] = df['locality'].replace('NULL', np.nan)\n",
    "df = df.dropna(subset=['locality'])\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning locality: {num_rows}\")\n",
    "\n",
    "# STEP 5, cleaning opening_date \n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows before opening_date cleaning: {num_rows}\")\n",
    "\n",
    "# Initialize a list to store invalid dates\n",
    "invalid_dates_list = []\n",
    "\n",
    "# Function to parse dates and standardize format\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        # Attempt to parse the date string to a datetime object\n",
    "        dt = parser.parse(date_str)\n",
    "        # Convert to the desired format (YYYY-MM-DD)\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except (parser.ParserError, ValueError):\n",
    "        # Append invalid date to the list\n",
    "        invalid_dates_list.append(date_str)\n",
    "        return np.nan  # Return NaN for invalid dates\n",
    "\n",
    "# Apply the function to the 'date_of_birth' column\n",
    "df['opening_date'] = df['opening_date'].apply(parse_date)\n",
    "\n",
    "# Identify rows that would be null after conversion\n",
    "invalid_rows = df[df['opening_date'].isna()]\n",
    "\n",
    "display(\"Rows that would be converted to NULL:\")\n",
    "display(invalid_rows)\n",
    "\n",
    "# Drop rows with NaN (invalid dates)\n",
    "df_cleaned = df.dropna(subset=['opening_date'])\n",
    "\n",
    "display(\"\\nList of invalid dates:\")\n",
    "display(invalid_dates_list)\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows after opening_date cleaning: {num_rows}\")\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning: {num_rows}\")\n",
    "\n",
    "#returning the dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before opening_date cleaning: 441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Rows that would be converted to NULL:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, address, longitude, lat, locality, store_code, staff_numbers, opening_date, store_type, latitude, country_code, continent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nList of invalid dates:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after opening_date cleaning: 441\n"
     ]
    }
   ],
   "source": [
    "# STEP 6 clean date of birth \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to text data \n",
    "def clean_text_data(connection, table_name, column_name):\n",
    "    clean_text_sql = f\"\"\"\n",
    "    UPDATE \"{table_name}\"\n",
    "    SET \"{column_name}\" = NULL\n",
    "    WHERE CAST(\"{column_name}\" AS TEXT) !~ '^[A-Za-z_]+$';\n",
    "    \"\"\"\n",
    "    connection.execute(text(clean_text_sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING OUTS BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N/A', 'High Wycombe', 'Landshut', 'Westbury', 'Belper',\n",
       "       'Gainsborough', 'Rutherglen', 'Stuttgart', 'Kaukauna', 'Hartley',\n",
       "       'Siegburg', 'Devizes', 'Crystal Lake', 'Halstenbek', 'Lancing',\n",
       "       'Newbury', 'Lymington', 'Chapletown', 'Barnet', 'East Dereham',\n",
       "       'Poulton-le-Fylde', 'Bushey', 'Ehingen', 'Aberdeen', 'Surbiton',\n",
       "       'Inverness', 'Weimar', 'Penzance', 'Albstadt', 'Hechingen',\n",
       "       'Mexborough', 'Arbroath', 'Cowes', 'Clacton-on-Sea', 'Boston',\n",
       "       'Charlottenburg-Nord', 'Bretten', 'Sun City Center', 'Karben',\n",
       "       'Martinsburg', 'Oschatz', 'Kingston upon Hull', 'Leyland',\n",
       "       'Venice', 'Schleswig', 'Eppingen', '9IBH8Y4Z0S', 'Losheim',\n",
       "       'Burscheid', 'Southsea', 'Porterville', 'Walsrode', 'Exeter',\n",
       "       'Thetford', 'Morningside Heights', 'Searcy', 'Radevormwald',\n",
       "       'Stade', 'Mira Mesa', 'Strood', 'Verl', 'Wesseling', 'Pfullingen',\n",
       "       'Bensheim', 'Walton-on-the-Naze', 'Friedberg', 'Winsford',\n",
       "       'Newburgh', 'Selby', 'Oberhausen', 'Zeitz', 'Viewpark',\n",
       "       'Rhosllanerchrugog', 'Marburg an der Lahn', 'Waverly', 'Memmingen',\n",
       "       'Trossingen', 'Dahlem', '1T6B406CI8', 'Lower Earley',\n",
       "       'Barmbek-Nord', 'Bad Segeberg', 'Great Wyrley', 'Nidderau',\n",
       "       'Jersey City', 'Fayetteville', 'Gauting', 'NULL', 'Blackpool',\n",
       "       'Redding', 'Hofheim am Taunus', '6LVWPU1G64', 'Wittenau',\n",
       "       'Aschaffenburg', 'Fairview Heights', 'Sicklerville',\n",
       "       'Brierley Hill', 'Kirchlengern', 'Port Richmond', 'Belle Glade',\n",
       "       'Reutlingen', 'Brunswick', 'Gronau', 'Gifhorn', 'Carlsbad', 'Lutz',\n",
       "       'Sterling', 'RX9TCP2RGB', 'Korschenbroich', 'Hutchinson',\n",
       "       'Scarsdale', 'Iron River', 'Jackson', 'CQMHKI78BX', 'Bridgeport',\n",
       "       'Rudolstadt', 'Hermsdorf', 'Neuburg an der Donau', 'Bad Honnef',\n",
       "       'Scottsdale', 'RY6K0AUE7F', 'Troutdale', 'Columbia Heights',\n",
       "       'Westchester', '3VHFDNP8ET'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['locality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where 'lat' is 'N/A':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>325</td>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>None</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index address longitude  lat locality    store_code staff_numbers  \\\n",
       "0      0     N/A       N/A  N/A      N/A  WEB-1388012W           325   \n",
       "\n",
       "  opening_date  store_type latitude country_code continent  \n",
       "0   2010-06-12  Web Portal     None           GB    Europe  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, address, longitude, lat, locality, store_code, staff_numbers, opening_date, store_type, latitude, country_code, continent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Locate the row(s) where 'lat' is 'N/A'\n",
    "na_rows = df.loc[df['lat'] == 'N/A']\n",
    "\n",
    "null_rows = df.loc[df['lat'] == 'NULL']\n",
    "\n",
    "\n",
    "# Print the 'N/A' row(s) for visual inspection\n",
    "print(\"Rows where 'lat' is 'N/A':\")\n",
    "display(na_rows)\n",
    "display(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 441 entries, 0 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          441 non-null    int64 \n",
      " 1   address        441 non-null    object\n",
      " 2   longitude      441 non-null    object\n",
      " 3   lat            1 non-null      object\n",
      " 4   locality       441 non-null    object\n",
      " 5   store_code     441 non-null    object\n",
      " 6   staff_numbers  441 non-null    object\n",
      " 7   opening_date   441 non-null    object\n",
      " 8   store_type     441 non-null    object\n",
      " 9   latitude       440 non-null    object\n",
      " 10  country_code   441 non-null    object\n",
      " 11  continent      441 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 44.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Define the regex pattern to match invalid latitude values\n",
    "pattern = r'^[A-Za-z0-9]+$'\n",
    "\n",
    "# Create a boolean mask for rows to keep: rows that do not match the pattern and are not 'NULL' or 'N/A'\n",
    "mask = ~df['lat'].str.contains(pattern, na=False) & ~df['lat'].isin(['NULL'])\n",
    "\n",
    "# Filter the DataFrame using the mask\n",
    "df = df[mask]\n",
    "\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 441 entries, 0 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          441 non-null    int64 \n",
      " 1   address        441 non-null    object\n",
      " 2   longitude      441 non-null    object\n",
      " 3   lat            1 non-null      object\n",
      " 4   locality       441 non-null    object\n",
      " 5   store_code     441 non-null    object\n",
      " 6   staff_numbers  441 non-null    object\n",
      " 7   opening_date   441 non-null    object\n",
      " 8   store_type     441 non-null    object\n",
      " 9   latitude       440 non-null    object\n",
      " 10  country_code   441 non-null    object\n",
      " 11  continent      441 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 44.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with non-string values in 'locality' column:\n",
      "Empty DataFrame\n",
      "Columns: [index, address, longitude, lat, locality, store_code, staff_numbers, opening_date, store_type, latitude, country_code, continent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if 'locality' column contains any non-string values\n",
    "non_string_values = df[~df['locality'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Display the non-string values\n",
    "print(\"Rows with non-string values in 'locality' column:\")\n",
    "print(non_string_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N/A', 'High Wycombe', 'Landshut', 'Westbury', 'Belper',\n",
       "       'Gainsborough', 'Rutherglen', 'Stuttgart', 'Kaukauna', 'Hartley',\n",
       "       'Siegburg', 'Devizes', 'Crystal Lake', 'Halstenbek', 'Lancing',\n",
       "       'Newbury', 'Lymington', 'Chapletown', 'Barnet', 'East Dereham',\n",
       "       'Poulton-le-Fylde', 'Bushey', 'Ehingen', 'Aberdeen', 'Surbiton',\n",
       "       'Inverness', 'Weimar', 'Penzance', 'Albstadt', 'Hechingen',\n",
       "       'Mexborough', 'Arbroath', 'Cowes', 'Clacton-on-Sea', 'Boston',\n",
       "       'Charlottenburg-Nord', 'Bretten', 'Sun City Center', 'Karben',\n",
       "       'Martinsburg', 'Oschatz', 'Kingston upon Hull', 'Leyland',\n",
       "       'Venice', 'Schleswig', 'Eppingen', 'Losheim', 'Burscheid',\n",
       "       'Southsea', 'Porterville', 'Walsrode', 'Exeter', 'Thetford',\n",
       "       'Morningside Heights', 'Searcy', 'Radevormwald', 'Stade',\n",
       "       'Mira Mesa', 'Strood', 'Verl', 'Wesseling', 'Pfullingen',\n",
       "       'Bensheim', 'Walton-on-the-Naze', 'Friedberg', 'Winsford',\n",
       "       'Newburgh', 'Selby', 'Oberhausen', 'Zeitz', 'Viewpark',\n",
       "       'Rhosllanerchrugog', 'Marburg an der Lahn', 'Waverly', 'Memmingen',\n",
       "       'Trossingen', 'Dahlem', 'Lower Earley', 'Barmbek-Nord',\n",
       "       'Bad Segeberg', 'Great Wyrley', 'Nidderau', 'Jersey City',\n",
       "       'Fayetteville', 'Gauting', 'Blackpool', 'Redding',\n",
       "       'Hofheim am Taunus', 'Wittenau', 'Aschaffenburg',\n",
       "       'Fairview Heights', 'Sicklerville', 'Brierley Hill',\n",
       "       'Kirchlengern', 'Port Richmond', 'Belle Glade', 'Reutlingen',\n",
       "       'Brunswick', 'Gronau', 'Gifhorn', 'Carlsbad', 'Lutz', 'Sterling',\n",
       "       'Korschenbroich', 'Hutchinson', 'Scarsdale', 'Iron River',\n",
       "       'Jackson', 'Bridgeport', 'Rudolstadt', 'Hermsdorf',\n",
       "       'Neuburg an der Donau', 'Bad Honnef', 'Scottsdale', 'Troutdale',\n",
       "       'Columbia Heights', 'Westchester'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['locality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where 'locality' is 'N/A':\n",
      "   index address longitude  lat locality    store_code staff_numbers  \\\n",
      "0      0     N/A       N/A  N/A      N/A  WEB-1388012W           325   \n",
      "\n",
      "  opening_date  store_type latitude country_code continent  \n",
      "0   2010-06-12  Web Portal     None           GB    Europe  \n",
      "\n",
      "Rows where 'locality' is None or NaN:\n",
      "Empty DataFrame\n",
      "Columns: [index, address, longitude, lat, locality, store_code, staff_numbers, opening_date, store_type, latitude, country_code, continent]\n",
      "Index: []\n",
      "\n",
      "Rows where 'locality' is 'NULL':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, address, longitude, lat, locality, store_code, staff_numbers, opening_date, store_type, latitude, country_code, continent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Find rows where 'locality' is 'N/A'\n",
    "locality_na = df.loc[df['locality'] == 'N/A']\n",
    "\n",
    "# Find rows where 'locality' is None or NaN\n",
    "locality_none = df.loc[pd.isna(df['locality'])]\n",
    "\n",
    "# Find rows where 'locality' is 'NULL'\n",
    "locality_null = df.loc[df['locality'] == 'NULL']\n",
    "\n",
    "# Display the results\n",
    "print(\"Rows where 'locality' is 'N/A':\")\n",
    "print(locality_na)\n",
    "\n",
    "print(\"\\nRows where 'locality' is None or NaN:\")\n",
    "print(locality_none)\n",
    "\n",
    "print(\"\\nRows where 'locality' is 'NULL':\")\n",
    "display(locality_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 451 entries, 0 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          451 non-null    int64 \n",
      " 1   address        451 non-null    object\n",
      " 2   longitude      451 non-null    object\n",
      " 3   lat            11 non-null     object\n",
      " 4   locality       451 non-null    object\n",
      " 5   store_code     451 non-null    object\n",
      " 6   staff_numbers  451 non-null    object\n",
      " 7   opening_date   451 non-null    object\n",
      " 8   store_type     451 non-null    object\n",
      " 9   latitude       450 non-null    object\n",
      " 10  country_code   451 non-null    object\n",
      " 11  continent      451 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 42.4+ KB\n",
      "None\n",
      "lat ['N/A', '13KJZ890JH', '2XE1OWOC23', 'OXVE5QR07O', 'VKA5I8H32X', 'LACCWDI0SB', 'A3O5CBWAMD', 'UXMWDMX1LC']\n",
      "str: []\n",
      "nonetype [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "empty []\n",
      "null string: ['NULL', 'NULL', 'NULL']\n",
      "lat ['N/A', '13KJZ890JH', '2XE1OWOC23', 'OXVE5QR07O', 'VKA5I8H32X', 'LACCWDI0SB', 'A3O5CBWAMD', 'UXMWDMX1LC', 'N/A', '13KJZ890JH', '2XE1OWOC23', 'OXVE5QR07O', 'VKA5I8H32X', 'LACCWDI0SB', 'A3O5CBWAMD', 'UXMWDMX1LC']\n",
      "str: []\n",
      "nonetype [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "empty []\n",
      "null string: ['NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL']\n"
     ]
    }
   ],
   "source": [
    "#sandbox for 'lat'\n",
    "\n",
    "# print df\n",
    "print(df.info())\n",
    "\n",
    "# create empty list for lat_items \n",
    "str_items = []\n",
    "nonetype_items = []\n",
    "empty_items = [] \n",
    "lat_items = []\n",
    "null_str_items = [] \n",
    "\n",
    "# Go through the series 'lat' and append each item to lat_items\n",
    "for x in df['lat']:\n",
    "    if x is None: \n",
    "        #print('Nonetype:')\n",
    "        nonetype_items.append(x)\n",
    "    elif x == 'None':  # Check for string 'None'\n",
    "        #print('string')\n",
    "        str_items.append(x)\n",
    "    elif x == 'NULL':\n",
    "        #print('string')\n",
    "        null_str_items.append(x)\n",
    "    elif x == '':  # Check for empty string\n",
    "        #print('empty string:')\n",
    "        empty_items.append(x)\n",
    "    else:\n",
    "        #print('dont know')\n",
    "        lat_items.append(x)\n",
    "\n",
    "# Print out lat_items\n",
    "print('lat', lat_items)\n",
    "print('str:', str_items) \n",
    "print('nonetype', nonetype_items)\n",
    "print('empty', empty_items)\n",
    "print('null string:', null_str_items)\n",
    "\n",
    "# drop na rows from the 'lat' column \n",
    "#df = df.dropna(subset=['lat'])\n",
    "\n",
    "# # Define the regex pattern\n",
    "# string_pattern = r'^[A-Za-z0-9]+$'\n",
    "\n",
    "# # Fill NaN values with a placeholder that does not match the regex\n",
    "# df['lat'] = df['lat'].fillna('@@@')\n",
    "\n",
    "# # Filter rows where 'lat' matches the pattern\n",
    "# df = df[df['lat'].str.match(string_pattern)]\n",
    "\n",
    "# # Reset 'lat' column to NaN where the placeholder was used\n",
    "# df['lat'] = df['lat'].replace('placeholder', np.nan)\n",
    "\n",
    "# Go through the series 'lat' and append each item to lat_items\n",
    "for x in df['lat']:\n",
    "    if x is None: \n",
    "        #print('Nonetype:')\n",
    "        nonetype_items.append(x)\n",
    "    elif x == 'None':  # Check for string 'None'\n",
    "        #print('string')\n",
    "        str_items.append(x)\n",
    "    elif x == 'NULL':\n",
    "        #print('string')\n",
    "        null_str_items.append(x)\n",
    "    elif x == '':  # Check for empty string\n",
    "        #print('empty string:')\n",
    "        empty_items.append(x)\n",
    "    else:\n",
    "        #print('dont know')\n",
    "        lat_items.append(x)\n",
    "\n",
    "# Print out lat_items\n",
    "print('lat', lat_items)\n",
    "print('str:', str_items) \n",
    "print('nonetype', nonetype_items)\n",
    "print('empty', empty_items)\n",
    "print('null string:', null_str_items)\n",
    "\n",
    "\n",
    "# go through the remaining lat items and add them to new_lat_items\n",
    "# new_lat_items = [] \n",
    "# for x in df['lat']:\n",
    "#     new_lat_items.append(x)\n",
    "\n",
    "# print new lat items \n",
    "# print(new_lat_items)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, 63 to 447\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          10 non-null     int64 \n",
      " 1   address        10 non-null     object\n",
      " 2   longitude      10 non-null     object\n",
      " 3   lat            10 non-null     object\n",
      " 4   locality       10 non-null     object\n",
      " 5   store_code     10 non-null     object\n",
      " 6   staff_numbers  10 non-null     object\n",
      " 7   opening_date   10 non-null     object\n",
      " 8   store_type     10 non-null     object\n",
      " 9   latitude       10 non-null     object\n",
      " 10  country_code   10 non-null     object\n",
      " 11  continent      10 non-null     object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows store data before cleaning: 451\n",
      "<class 'pandas.core.series.Series'>\n",
      "List of non-matching card numbers: ['None', '1CJ5OAU4BR', '3ZR3F89D97', 'NULL', 'L13EQEQODP', 'J3BPB68Z1J', 'AJHOMDOHZ4', 'NULL', 'AE7EEW4HSS', 'NULL', 'JZP8MIJTPZ']\n",
      "11\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 440 entries, 1 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          440 non-null    int64 \n",
      " 1   address        440 non-null    object\n",
      " 2   longitude      440 non-null    object\n",
      " 3   lat            0 non-null      object\n",
      " 4   locality       440 non-null    object\n",
      " 5   store_code     440 non-null    object\n",
      " 6   staff_numbers  440 non-null    object\n",
      " 7   opening_date   440 non-null    object\n",
      " 8   store_type     440 non-null    object\n",
      " 9   latitude       440 non-null    object\n",
      " 10  country_code   440 non-null    object\n",
      " 11  continent      440 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 44.7+ KB\n",
      "None\n",
      "Number of rows store data after cleaning latitide column: 440\n"
     ]
    }
   ],
   "source": [
    "#sandbox for latitde \n",
    " \n",
    "#df.info()\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data before cleaning: {num_rows}\")\n",
    "\n",
    "df['latitude']\n",
    "\n",
    "print(type(df['latitude']))\n",
    "\n",
    "# Create an empty list to store non-matching card numbers\n",
    "non_matching = []\n",
    "\n",
    "# Define a regular expression pattern for numbers only\n",
    "pattern = r'^-?\\d+(\\.\\d+)?$'\n",
    "\n",
    "# Ensure all elements in the 'card_number' column are strings\n",
    "df['latitude'] = df['latitude'].astype(str)\n",
    "\n",
    "for x in df['latitude']:\n",
    "    if not re.match(pattern, str(x)):\n",
    "        non_matching.append(x)\n",
    "\n",
    "# Print the list of non-matching card numbers\n",
    "print(\"List of non-matching card numbers:\", non_matching)\n",
    "print(len(non_matching))\n",
    "\n",
    "df = df[df['latitude'].apply(lambda x: bool(re.match(pattern, x)))]\n",
    "\n",
    "\n",
    "# df = df.dropna(subset=['latitude'])\n",
    "print(df.info())\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning latitide column: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 451 entries, 0 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          451 non-null    int64 \n",
      " 1   address        451 non-null    object\n",
      " 2   longitude      451 non-null    object\n",
      " 3   lat            11 non-null     object\n",
      " 4   locality       451 non-null    object\n",
      " 5   store_code     451 non-null    object\n",
      " 6   staff_numbers  451 non-null    object\n",
      " 7   opening_date   451 non-null    object\n",
      " 8   store_type     451 non-null    object\n",
      " 9   latitude       450 non-null    object\n",
      " 10  country_code   451 non-null    object\n",
      " 11  continent      451 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 42.4+ KB\n",
      "Number of rows store data before cleaning: 451\n",
      "Number of rows store data after cleaning latitide column: 440\n",
      "Number of rows store data after dropping lat column: 440\n",
      "Number of rows store data after cleaning locality: 440\n",
      "Number of rows store data after cleaning continent: 440\n",
      "Number of rows store data after cleaning opening date: 428\n",
      "Number of rows store data after cleaning: 428\n"
     ]
    }
   ],
   "source": [
    "# code to clean the dataframe \n",
    "# Number of rows store data before cleaning: 451\n",
    "# Number of rows store data after dropping lat and cleaning latitide column: 440\n",
    "# Number of rows store data after cleaning locality: 440\n",
    "# Number of rows store data after cleaning continent: 440\n",
    "# Number of rows store data after cleaning opening date: 428\n",
    "# Number of rows store data after cleaning: 428\n",
    "\n",
    "df.info()\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data before cleaning: {num_rows}\")\n",
    "\n",
    "# Clean the latitude column\n",
    "\n",
    "\n",
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['latitude'])\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning latitide column: {num_rows}\")\n",
    "\n",
    "# Dropping the 'latitude' column as it's empty \n",
    "df = df.drop(columns=['lat'])\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after dropping lat column: {num_rows}\")\n",
    "\n",
    "# filtering out items in locality that aren't real place names or NULL \n",
    "pattern = r'^[a-zA-Z\\s-]+$'\n",
    "df = df[df['locality'].str.match(pattern)]\n",
    "df['locality'] = df['locality'].replace('NULL', np.nan)\n",
    "df = df.dropna(subset=['locality'])\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning locality: {num_rows}\")\n",
    "\n",
    "# replacing incorrect spellings of continents \n",
    "continent_replacements = {\n",
    "    'eeEurope': 'Europe',\n",
    "    'eeAmerica': 'America'\n",
    "}\n",
    "\n",
    "df['continent'] = df['continent'].replace(continent_replacements)\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning continent: {num_rows}\")\n",
    "\n",
    "# LOGGING: checking everything has worked \n",
    "#print(df['continent'].unique())\n",
    "#print(df['store_type'].unique()) \n",
    "#print(df['country_code'].unique()) \n",
    "#print(df['continent'].unique())\n",
    "\n",
    "# LOGGING: checking of datetime before is datetime64 datetype  \n",
    "#is_datetime_before = pd.api.types.is_datetime64_any_dtype(df['opening_date'])\n",
    "\n",
    "# converting opening date to datetime object \n",
    "df['opening_date'] = pd.to_datetime(df['opening_date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# dropping any rows which contain missing values  \n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning opening date: {num_rows}\")\n",
    "\n",
    "# LOGGING: checking the conversion worked \n",
    "#is_datetime_after = pd.api.types.is_datetime64_any_dtype(df['opening_date'])\n",
    "#print(f\"Is 'dates' column datetime64 dtype? {is_datetime_before}\")\n",
    "#print(f\"Is 'dates' column datetime64 dtype? {is_datetime_after}\")\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows store data after cleaning: {num_rows}\")\n",
    "#returning the dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "non_matching_cards = []\n",
    "strings = []\n",
    "numbers = []\n",
    "\n",
    "for x in df['card_number']:\n",
    "    if isinstance(x, str):\n",
    "        strings.append(x)\n",
    "    elif isinstance(x, int):\n",
    "        numbers.append(x)\n",
    "    else:\n",
    "        non_matching_cards.append(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinational_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
